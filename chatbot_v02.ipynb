{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a62190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import langchain\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2e9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6be1c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma, DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac093d7-fb03-4287-92f6-279d7a19add4",
   "metadata": {},
   "source": [
    "##### texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d060d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature = 0.0) # language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c04189-44fb-4493-a23c-20ce1e8fc062",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3552c758",
   "metadata": {},
   "source": [
    "### notes:\n",
    "chain_type = \n",
    "- map_reduce: look at all documents that might contain the answer and returns the summary as the final answer. Can work with any number of documents. Treat each document independantly -> may lead to redundancy. makes many calls. can be batched and run parallel. Can also be used for summarization\n",
    "- Refine: builds upon the answer of the previos document. slow.\n",
    "- map_rerank: do a single call to each document, score each answer and chooses the highest score as the respond. SHould be refined by explaining to the model how to define the scoring and how to choose the best one.\n",
    "- stuff_method: combines all documents into one and extract the answer from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f489ff49-38b8-4436-b713-642ff8510cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5197f441-7b3a-42bd-8efa-c302f3c5a98f",
   "metadata": {},
   "source": [
    "# Loading all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef35d4b6-da20-45e9-a418-07618782a197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Personal Email: N/A'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_htmls():\n",
    "    all_files = [f for f in os.listdir('data') if f.endswith('.html')] # every html file in the folder\n",
    "    docs = []\n",
    "    for file in all_files:\n",
    "        doc = UnstructuredHTMLLoader('data/'+file).load() # loading each document\n",
    "        parsed_doc_name = file.split('/')[0].split('_') \n",
    "        first_name = parsed_doc_name[0]\n",
    "        last_name = parsed_doc_name[1]\n",
    "        doc_type = parsed_doc_name[2].split('.')[0] \n",
    "        # print(f'name:{first_name}, family_name:{last_name}, doc_type = {doc_type}')\n",
    "        # adding to each document metadata for later easier search\n",
    "        doc[0].metadata['name'] = ' '.join([first_name, last_name])\n",
    "        doc[0].metadata['doc_type'] = doc_type # -> may not use it, keeping it for now\n",
    "        docs.extend(doc)\n",
    "    return docs\n",
    "\n",
    "# test = load_htmls()\n",
    "# test[-1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09d65742-0892-446e-b9c5-7f6bf93e91d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mariann Avocado',\n",
       " 'Hanna Smith',\n",
       " 'Jared Livinglife',\n",
       " 'Zeus Manly',\n",
       " 'Velvet Throat',\n",
       " 'Helen Troy',\n",
       " 'Julia Harpman',\n",
       " 'Robert King',\n",
       " 'Aphrodite Greek',\n",
       " 'Jerry Smith']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_names(docs = None):\n",
    "    ''' get a list of all names'''\n",
    "    if docs is None:\n",
    "        docs = load_htmls()\n",
    "    return list(set([doc.metadata['name'] for doc in docs]))\n",
    "\n",
    "get_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa9edb-58eb-4ec4-93ff-d5642f5af9c7",
   "metadata": {},
   "source": [
    "## Name based retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "995f5ac1-157b-46f6-8bf5-5a69caa4685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_based_retriever(docs = None, name = 'All', embeddings = OpenAIEmbeddings(), chunk_size = 1000, chunk_overlap = 0):\n",
    "    '''\n",
    "    Creats custom retriever based on the name chosen by the user\n",
    "    '''\n",
    "    if docs == None:\n",
    "        docs = load_htmls()\n",
    "    \n",
    "    if name == 'All':\n",
    "        print('all')\n",
    "        documents = docs\n",
    "    else:\n",
    "        print(f'name is {name}')\n",
    "        documents = [doc for doc in docs if doc.metadata['name'] == name] \n",
    "    # split the documents into chunks\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "\n",
    "    #vector database\n",
    "    db = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "    # expose this index in a retriever interface\n",
    "    client_filter = {'client_name': {'$eq': name}}\n",
    "    retriever = db.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": 5}\n",
    "    )\n",
    "    \n",
    "    return retriever, texts\n",
    "\n",
    "# r, t = name_based_retriever(docs = None, name = 'Mariann Avocado')\n",
    "# t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "365e23e4-82e7-4a43-bed9-0afb76d1ed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name is Robert King\n"
     ]
    }
   ],
   "source": [
    "name = 'Robert King'\n",
    "r, t = name_based_retriever(docs = None, name = name)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(),\n",
    "    chain_type=\"map_reduce\",\n",
    "    retriever=r,\n",
    "    return_source_documents=False,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "201c7063-96a3-4939-8f19-46d35df8db4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Velvet Throat works in the hospitality industry.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('What industry does Velvet Throat work at?')['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "849b6e79-3fe2-4c2d-b18e-acafc3ca33a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Robert King works in the hedge fund industry.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(f'What industry does {name} work at?')['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd4a22b4-11eb-4818-896e-3c28314deae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Robert King has donated $1 million to a local charity, the Red Cross, $500,000 to the Boys & Girls Club, $250,000 to Habitat for Humanity, $100,000 to the Democratic National Committee, and $50,000 to the California Democratic Party.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(f'Where has {name} donated money to?')['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ad521c",
   "metadata": {},
   "source": [
    "# Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd876d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ergo_\\Anaconda3\\envs\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58b48311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_and_history(input, history, name, llm = llm, verbose = True): \n",
    "    '''\n",
    "    Here we are getting the user chat history and storing it in a list and adding it to the previous state.\n",
    "    input: question\n",
    "    history: state\n",
    "    name: client name from dropdown\n",
    "    llm: llm model\n",
    "    retriever: RAG\n",
    "    '''\n",
    "    history = history or [] \n",
    "    print(history) \n",
    "    s = list(sum(history, ())) \n",
    "    print(s) \n",
    "    s.append(input) \n",
    "    print('#########################################') \n",
    "    print(s) \n",
    "    inp = ' '.join(s) \n",
    "    print(inp)\n",
    "    print(f' chosen name is {name}')\n",
    "    retriever, texts = name_based_retriever(docs = None, name = name)\n",
    "    output = api_calling(question = inp, llm = llm, retriever = retriever, verbose = verbose) \n",
    "    history.append((input, output)) \n",
    "    print('------------------') \n",
    "    print(history) \n",
    "    print(\"*********************\") \n",
    "    return history, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9949b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_calling(question, llm, retriever, chain_type = 'map_reduce', verbose = True): \n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm = llm # text generation model at the end\n",
    "        , chain_type = chain_type\n",
    "        , retriever = retriever #interface for fetching documents\n",
    "        , verbose = verbose\n",
    "    )\n",
    "    respond = qa.run(question)\n",
    "    \n",
    "    return respond\n",
    "\n",
    "# api_calling(question = 'Who is the article about?', llm = llm, retriever = retriever, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb772466-39e3-473d-ad13-3dd6fed1155a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompt = 'How can I help you?'\n",
    "theme = gr.themes.Monochrome() #gr.themes.Soft() \n",
    "block = gr.Blocks(theme = theme)\n",
    "with block:\n",
    "    gr.Markdown('''<h1><center> Let's Learn More About Our (Prospective) Client! </center></h1>''')\n",
    "    entity_name = gr.Dropdown(choices = sorted(['All']+get_names()), multiselect = False, label = \"Choose or type in the entity's name\", value = 'All')\n",
    "    chatbot = gr.Chatbot()\n",
    "    message = gr.Textbox(placeholder = prompt, label = 'Type here:')\n",
    "    state = gr.State()\n",
    "    submit = gr.Button('SEND')\n",
    "    submit.click(fn = message_and_history,\n",
    "                 inputs = [message, state, entity_name],\n",
    "                 outputs = [chatbot, state])\n",
    "\n",
    "block.launch(share = True)\n",
    "# name                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8acc314d-31c8-406d-bfaa-f7e321b61733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
